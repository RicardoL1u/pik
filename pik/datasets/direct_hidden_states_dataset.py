import pandas as pd
import numpy as np
import torch
from torch.utils.data import Dataset
import logging
import json
from collections import defaultdict
from typing import List, Optional, Union
import torch
class DirectHiddenStatesDataset(Dataset):
    '''
    Loads the hidden states dataset and text generations from files generated by `generate.py`.
    '''
    def __init__(self,
                 hs_file='hidden_states.pt',
                 tg_file='text_generations.json',
                 precision=torch.float16,
                 layer_idx: Optional[Union[int, List[int]]] = None,  
                 rebalance: bool = False,
                 # layer_idx could be a list of integers or a single integer
                 device='cuda'):
        self.layer_idx = layer_idx
        self.device = device
        hs = torch.load(hs_file, map_location='cpu').type(precision)
        logging.info('hs.shape={}'.format(hs.shape))
        assert hs.dim() in (2, 3)

        if self.layer_idx is None:
            logging.info('Using all layers')
            if hs.dim() == 3:
                hs = hs.reshape(hs.shape[0], -1)
        else:
            if isinstance(self.layer_idx, int):
                self.layer_idx = [self.layer_idx]
            assert all(isinstance(i, int) for i in self.layer_idx), "layer_idx must be a list of integers"
            logging.info('Using layers {}'.format(self.layer_idx))
            hs = hs[:, self.layer_idx, :].reshape(hs.shape[0], -1)

        self.hidden_states = hs
        logging.info('hidden_states.shape={}'.format(self.hidden_states.shape))

        self.text_generations: list = json.load(open(tg_file, 'r'))

            
        keep_idx_list = []
        if 'trivia_qa' in tg_file:
            # only keeps the text_generation and hidden_states that
            # answer_type == 'WikipediaEntity'
            for i, sample in enumerate(self.text_generations):
                if sample['answer']['type'] == 'WikipediaEntity':
                    keep_idx_list.append(i)
        else:
            # keep all
            keep_idx_list = list(range(len(self.text_generations)))
        
        # remove samples that are not WikipediaEntity
        self.text_generations = [self.text_generations[i] for i in keep_idx_list]
        # same for hidden_states
        self.hidden_states = self.hidden_states[keep_idx_list]
        
        
        # Create pik_labels using a vectorized operation
        self.pik_labels = np.array([sample['consistency'] for sample in self.text_generations])
        # convert to torch tensor
        self.pik_labels = torch.from_numpy(self.pik_labels).type(precision)
        
        # Assert there is no nan in pik_labels
        # assert not np.isnan(self.pik_labels).any(), 'pik_labels contains nan'
        assert len(self.pik_labels) == len(self.hidden_states), 'pik_labels len={} != hidden_states len={}'.format(len(self.pik_labels), len(self.hidden_states))
        
        if rebalance:
            logging.info('Rebalancing dataset')
            logging.info('Before rebalancing, hidden_states.shape={}'.format(self.hidden_states.shape))
            self._rebalance()
            logging.info('After rebalancing, hidden_states.shape={}'.format(self.hidden_states.shape))
            

    def __len__(self):
        return self.hidden_states.shape[0]

    def __getitem__(self, i):
        return (
            self.hidden_states[i],
            self.pik_labels[i],
        )
  
    def get_pik_label(self, hid):
        return self.pik_labels[hid]
    
